{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/miniconda3/envs/rl/lib/python3.11/site-packages/flax/core/meta.py:31: DeprecationWarning: jax.experimental.maps and jax.experimental.maps.xmap are deprecated and will be removed in a future release. Use jax.experimental.shard_map or jax.vmap with the spmd_axis_name argument for expressing SPMD device-parallel computations. Please file an issue on https://github.com/google/jax/issues if neither jax.experimental.shard_map nor jax.vmap are suitable for your use case.\n",
      "  from jax.experimental import maps\n",
      "/home/charles/miniconda3/envs/rl/lib/python3.11/site-packages/jax/_src/interpreters/xla.py:155: RuntimeWarning: overflow encountered in cast\n",
      "  return np.asarray(x, dtypes.canonicalize_dtype(x.dtype))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax\n",
    "from jax import jit, vmap\n",
    "\n",
    "import mujoco \n",
    "\n",
    "from mujoco import mjx\n",
    "\n",
    "from dm_control import mjcf\n",
    "from dm_control.locomotion.walkers import rescale\n",
    "\n",
    "import pickle\n",
    "\n",
    "from preprocessing.mjx_preprocess import process_clip\n",
    "\n",
    "# setup environment and stac data for preprocessing\n",
    "scale_factor = 0.9\n",
    "stac_path = \"./transform_snips.p\"\n",
    "\n",
    "with open(stac_path, \"rb\") as file:\n",
    "        d = pickle.load(file)        \n",
    "        data_qpos = d[\"qpos\"]\n",
    "        \n",
    "# Load rodent mjcf and rescale, then get the mj_model from that.\n",
    "# TODO: make this all work in mjx? james cotton did rescaling with mjx model:\n",
    "# https://github.com/peabody124/BodyModels/blob/f6ef1be5c5d4b7e51028adfc51125e510c13bcc2/body_models/biomechanics_mjx/forward_kinematics.py#L92\n",
    "root = mjcf.from_path(\"./assets/rodent.xml\")\n",
    "rescale.rescale_subtree(\n",
    "    root,\n",
    "    scale_factor,\n",
    "    scale_factor,\n",
    ")\n",
    "mj_model = mjcf.Physics.from_mjcf_model(root).model.ptr\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "    # Place into GPU\n",
    "mjx_model = mjx.put_model(mj_model)\n",
    "mjx_data = mjx.put_data(mj_model, mj_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_length = 250\n",
    "# Split clip like this if you want to run just once\n",
    "start_step = 0\n",
    "first_clip_qpos = data_qpos[start_step : start_step + clip_length]\n",
    "\n",
    "# jit the process_clip function\n",
    "jit_process_clip = jax.jit(process_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 250, 74)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape qposes to have the batch dimension and vmap the jitted function\n",
    "all_clips_qpos = data_qpos.reshape((-1, clip_length, mjx_model.nq))\n",
    "vmap_jit_process_clip = vmap(jit_process_clip, in_axes=(0, None, None))\n",
    "all_clips_qpos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clips = vmap_jit_process_clip(all_clips_qpos, mjx_model, mjx_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 250, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_clips.position.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving and loading (wip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_reference_clip_to_h5(filename, reference_clip):\n",
    "    \"\"\"\n",
    "    Save the contents of a ReferenceClip object to an .h5 file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the .h5 file to save to.\n",
    "        reference_clip (ReferenceClip): The ReferenceClip object to save.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'w') as hf:\n",
    "        for attr, value in reference_clip.__dict__.items():\n",
    "            if value is not None:\n",
    "                # Create a group for each batch\n",
    "                for batch_idx in range(value.shape[0]):\n",
    "                    #TODO: instead of batch_x, save as the name given by d[\"snips_order\"]\n",
    "                    # and save the order as its own thing at the top level\n",
    "                    group_name = f\"{attr}/batch_{batch_idx}\"\n",
    "                    hf.create_dataset(group_name, data=value[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test_all_clips.h5\"\n",
    "save_reference_clip_to_h5(filename, all_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.mjx_preprocess import ReferenceClip\n",
    "from jax import numpy as jp\n",
    "def load_reference_clip_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Load the contents of an .h5 file into a ReferenceClip object.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the .h5 file to load from.\n",
    "\n",
    "    Returns:\n",
    "        ReferenceClip: The reconstructed ReferenceClip object.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as hf:\n",
    "        clip = ReferenceClip()\n",
    "        for attr in clip.__dict__.keys():\n",
    "            batch_data = []\n",
    "            batch_idx = 0\n",
    "            while f\"{attr}/batch_{batch_idx}\" in hf:\n",
    "                batch_data.append(hf[f\"{attr}/batch_{batch_idx}\"][:])\n",
    "                batch_idx += 1\n",
    "            if batch_data:\n",
    "                setattr(clip, attr, jp.stack(batch_data))\n",
    "        return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position (842, 250, 3)\n",
      "quaternion (842, 250, 4)\n",
      "joints (842, 250, 67)\n",
      "body_positions (842, 250, 66, 3)\n",
      "velocity (842, 250, 3)\n",
      "joints_velocity (842, 250, 67)\n",
      "angular_velocity (842, 250, 3)\n",
      "body_quaternions (842, 250, 66, 4)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import fields\n",
    "\n",
    "for field in fields(all_clips):\n",
    "    print(field.name, getattr(all_clips, field.name).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FrozenInstanceError",
     "evalue": "cannot assign to field 'position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFrozenInstanceError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_all_clips \u001b[38;5;241m=\u001b[39m \u001b[43mload_reference_clip_from_h5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m, in \u001b[0;36mload_reference_clip_from_h5\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     20\u001b[0m         batch_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_data:\n\u001b[0;32m---> 22\u001b[0m         \u001b[38;5;28;43msetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clip\n",
      "File \u001b[0;32m<string>:4\u001b[0m, in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m: cannot assign to field 'position'"
     ]
    }
   ],
   "source": [
    "loaded_all_clips = load_reference_clip_from_h5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
