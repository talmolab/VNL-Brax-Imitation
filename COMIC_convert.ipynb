{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File `.p` Conversion from COMIC `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax\n",
    "from jax import random\n",
    "from envs.humanoid import HumanoidTracking\n",
    "import numpy as np\n",
    "import mediapy as media\n",
    "import jax.numpy as jp\n",
    "import mujoco\n",
    "from dm_control import mjcf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from dm_control import composer\n",
    "from dm_control.locomotion import arenas\n",
    "from dm_control.locomotion import walkers\n",
    "from walker import Rat\n",
    "from cmu_humanoid import CMUHumanoidPositionControlled\n",
    "from dm_control.locomotion.mocap import props\n",
    "from dm_control.locomotion.tasks.reference_pose import tracking\n",
    "from dm_control.locomotion.tasks.reference_pose import types\n",
    "from dm_control.utils import io as resources\n",
    "import os\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the h5 file hierarchy and the dataset shapes\n",
    "def print_hierarchy(h5file, indent=\"\"):\n",
    "    for key, item in h5file.items():\n",
    "        if isinstance(item, h5py.Group):\n",
    "            print(f\"{indent}{key} (Group)\")\n",
    "            print_hierarchy(item, indent + \"  \")\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            print(f\"{indent}{key} (Dataset): {item.shape}\")\n",
    "            \n",
    "filename = \"clips/test_trajectories.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    print(f\"Contents of {filename}:\")\n",
    "    print_hierarchy(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_h5_to_dict(file):\n",
    "    \"\"\"Recursively extract all datasets from the HDF5 group into a dictionary.\"\"\"\n",
    "    data_dict = {}\n",
    "    for key in file.keys():\n",
    "        if isinstance(file[key], h5py.Dataset):\n",
    "            # Store data as a numpy array\n",
    "            data_dict[key] = file[key][:]\n",
    "        elif isinstance(file[key], h5py.Group):\n",
    "            # Recursively process each group\n",
    "            data_dict.update({f\"{key}/{subkey}\": subvalue for subkey, subvalue in extract_h5_to_dict(file[key]).items()})\n",
    "    return data_dict\n",
    "\n",
    "# Path to your .h5 file\n",
    "file_path = 'clips/test_traj.h5'\n",
    "\n",
    "# Open the .h5 file and extract all data into a dictionary\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    all_data_dict = extract_h5_to_dict(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store specific data following the provided structure\n",
    "structured_data = {\n",
    "    'angular_velocity': all_data_dict.get('cmuv2019_001/walkers/walker_0/angular_velocity', None).T,\n",
    "    'appendages': all_data_dict.get('cmuv2019_001/walkers/walker_0/appendages', None).T,\n",
    "    'body_positions': all_data_dict.get('cmuv2019_001/walkers/walker_0/body_positions', None).T,\n",
    "    'body_quaternions': all_data_dict.get('cmuv2019_001/walkers/walker_0/body_quaternions', None).T,\n",
    "    'center_of_mass': all_data_dict.get('cmuv2019_001/walkers/walker_0/center_of_mass', None).T,\n",
    "    'end_effectors': all_data_dict.get('cmuv2019_001/walkers/walker_0/end_effectors', None).T,\n",
    "    'joints': all_data_dict.get('cmuv2019_001/walkers/walker_0/joints', None).T,\n",
    "    'joints_velocity': all_data_dict.get('cmuv2019_001/walkers/walker_0/joints_velocity', None).T,\n",
    "    'markers': all_data_dict.get('cmuv2019_001/walkers/walker_0/markers', None),\n",
    "    'position': all_data_dict.get('cmuv2019_001/walkers/walker_0/position', None).T,\n",
    "    'quaternion': all_data_dict.get('cmuv2019_001/walkers/walker_0/quaternion', None).T,\n",
    "    'scaling': all_data_dict.get('cmuv2019_001/walkers/walker_0/scaling', None),\n",
    "    'velocity': all_data_dict.get('cmuv2019_001/walkers/walker_0/velocity', None).T\n",
    "}\n",
    "\n",
    "# Optionally, print the data for verification\n",
    "for key, value in structured_data.items():\n",
    "    print(f\"{key}: {type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.array(structured_data[item]).shape for item in structured_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item for item in structured_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mocap_preprocess as mp\n",
    "mp.save_dataclass_pickle('clips/test_traj.p', structured_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if shape mataches\n",
    "1. for qpos stacks, `angular_velocity`, `veclocity` matches, `joints_velocity` doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'clips/humanoid_traj.p'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "print(type(data))\n",
    "print(data.joints_velocity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'clips/test_traj.p'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "print(type(data))\n",
    "print(data.joints_velocity.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our `humanoid_traj.p` to `.h5` For COMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['angular_velocity',\n",
    " 'appendages',\n",
    " 'body_positions',\n",
    " 'body_quaternions',\n",
    " 'center_of_mass',\n",
    " 'end_effectors',\n",
    " 'joints',\n",
    " 'joints_velocity',\n",
    " 'markers',\n",
    " 'position',\n",
    " 'quaternion',\n",
    " 'scaling',\n",
    " 'velocity']\n",
    "\n",
    "# Path to the pickle file and the desired output HDF5 file path\n",
    "pickle_file_path = 'clips/humanoid_traj.p'\n",
    "hdf5_file_path = 'humanoid_traj.h5'\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Create an HDF5 file and store the data\n",
    "with h5py.File(hdf5_file_path, 'w') as hdf_file:\n",
    "    for mocap in cat:\n",
    "        # Assuming each value is an array-like object that can be directly stored in HDF5\n",
    "        if isinstance(value, np.ndarray):\n",
    "            hdf_file.create_dataset(cat, data=data.mocap)\n",
    "        else:\n",
    "            print(f\"Skipping key {key} as it is not an array.\")\n",
    "print(f\"Data from {pickle_file_path} has been successfully written to {hdf5_file_path}.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
