env_name: rodent
algo_name: ppo
task_name: track
num_envs: 128
note: 
num_timesteps: 3_000_000_000
eval_every: 10_000
episode_length: 1000
batch_size: 32
learning_rate: 6e-4
num_minibatches: 32
num_updates_per_batch: 16
clipping_epsilon: 0.1
entropy_cost: 1e-2
# Either "mlp" or "intention"
policy_network_name: "mlp"
# currently use this for the output layer too.
kl_weight: 1e-6
# If using mlp policy network
mlp_policy_layer_sizes: [512, 512]
# If using intention policy network
encoder_layer_sizes: [512, 256]
intention_latent_size: 64
decoder_layer_sizes: [256, 512]

