env_name: humanoidtracking
algo_name: ppo
task_name: track
num_envs: 4096
note: 
num_timesteps: 10_000_000_000
eval_every: 10_000_000
episode_length: 1000
batch_size: 1024
learning_rate: 1e-4
num_minibatches: 32
num_updates_per_batch: 32
clipping_epsilon: 0.2
entropy_cost: 1e-2
# Either "mlp" or "intention"
policy_network_name: "intention"
# currently use this for the output layer too.
kl_weight: 0
# If using mlp policy network
mlp_policy_layer_sizes: [1024, 1024, 1024, 1024]
# If using intention policy network
encoder_layer_sizes: [1024, 1024]
intention_latent_size: 64
decoder_layer_sizes: [1024, 1024]

