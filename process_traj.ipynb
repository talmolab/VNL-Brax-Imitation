{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import mocap_preprocess as mp\n",
    "\n",
    "data_path = \"clips/all_snips.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"rb\") as f:\n",
    "    all_clips = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "snips_name_to_idx = {\n",
    "    name.split(\"/\")[-1].split(\".\")[0]: idx\n",
    "    for idx, name in enumerate(all_clips[\"snips_order\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snips_name_to_idx[\"Walk_49\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_step: 33000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'walker' has no attribute 'mocap_joints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m snips_name_to_idx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWalk_49\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwalk_49.p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/salk/rodent/VNL-Brax-Imitation-Intention/mocap_preprocess.py:79\u001b[0m, in \u001b[0;36mprocess\u001b[0;34m(stac_path, save_file, scale_factor, start_step, clip_length, n_steps, max_qvel, dt, adjust_z_offset, verbatim, ref_steps)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m end_step \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\n\u001b[1;32m     77\u001b[0m     [start_step \u001b[38;5;241m+\u001b[39m clip_length \u001b[38;5;241m+\u001b[39m max_reference_index, start_step \u001b[38;5;241m+\u001b[39m n_steps]\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 79\u001b[0m mocap_features \u001b[38;5;241m=\u001b[39m \u001b[43mget_mocap_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmocap_qpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_step\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwalker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# walker is rodent.Rat\u001b[39;49;00m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmj_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_qvel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43madjust_z_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbatim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m mocap_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaling\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m     90\u001b[0m mocap_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n",
      "File \u001b[0;32m~/Desktop/salk/rodent/VNL-Brax-Imitation-Intention/mocap_preprocess.py:127\u001b[0m, in \u001b[0;36mget_mocap_features\u001b[0;34m(mocap_qpos, walker, physics, max_qvel, dt, adjust_z_offset, verbatim, null_xyr, shift_position, shift_rotation)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert mocap_qpos to valid reference features.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    shift_rotation (bool, optional): Amount by which to shift the rotation.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Clip the angles.\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m joint_names \u001b[38;5;241m=\u001b[39m [b\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwalker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmocap_joints\u001b[49m]\n\u001b[1;32m    128\u001b[0m joint_ranges \u001b[38;5;241m=\u001b[39m physics\u001b[38;5;241m.\u001b[39mbind(walker\u001b[38;5;241m.\u001b[39mmocap_joints)\u001b[38;5;241m.\u001b[39mrange\n\u001b[1;32m    129\u001b[0m min_angles \u001b[38;5;241m=\u001b[39m joint_ranges[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'walker' has no attribute 'mocap_joints'"
     ]
    }
   ],
   "source": [
    "idx = snips_name_to_idx[\"Walk_49\"]\n",
    "mp.process(\n",
    "    data_path,\n",
    "    \"walk_49.p\",\n",
    "    start_step=idx * 250,\n",
    "    clip_length=250,\n",
    "    n_steps=250,\n",
    "    ref_steps=(1, 2, 3, 4, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of transform_snips_250.h5:\n",
      "clip_0 (Group)\n",
      "  props (Group)\n",
      "  walkers (Group)\n",
      "    walker_0 (Group)\n",
      "      angular_velocity (Dataset): (3, 256)\n",
      "      appendages (Dataset): (15, 256)\n",
      "      body_positions (Dataset): (54, 256)\n",
      "      body_quaternions (Dataset): (72, 256)\n",
      "      center_of_mass (Dataset): (3, 256)\n",
      "      end_effectors (Dataset): (12, 256)\n",
      "      joints (Dataset): (67, 256)\n",
      "      joints_velocity (Dataset): (67, 256)\n",
      "      markers (Dataset): (0,)\n",
      "      position (Dataset): (3, 256)\n",
      "      quaternion (Dataset): (4, 256)\n",
      "      scaling (Dataset): (0,)\n",
      "      velocity (Dataset): (3, 256)\n",
      "clip_250 (Group)\n",
      "  props (Group)\n",
      "  walkers (Group)\n",
      "    walker_0 (Group)\n",
      "      angular_velocity (Dataset): (3, 250)\n",
      "      appendages (Dataset): (15, 250)\n",
      "      body_positions (Dataset): (54, 250)\n",
      "      body_quaternions (Dataset): (72, 250)\n",
      "      center_of_mass (Dataset): (3, 250)\n",
      "      end_effectors (Dataset): (12, 250)\n",
      "      joints (Dataset): (67, 250)\n",
      "      joints_velocity (Dataset): (67, 250)\n",
      "      markers (Dataset): (0,)\n",
      "      position (Dataset): (3, 250)\n",
      "      quaternion (Dataset): (4, 250)\n",
      "      scaling (Dataset): (0,)\n",
      "      velocity (Dataset): (3, 250)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Prints the h5 file hierarchy and the dataset shapes\n",
    "def print_hierarchy(h5file, indent=\"\"):\n",
    "    for key, item in h5file.items():\n",
    "        if isinstance(item, h5py.Group):\n",
    "            print(f\"{indent}{key} (Group)\")\n",
    "            print_hierarchy(item, indent + \"  \")\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            print(f\"{indent}{key} (Dataset): {item.shape}\")\n",
    "\n",
    "\n",
    "filename = \"transform_snips_250.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    print(f\"Contents of {filename}:\")\n",
    "    print_hierarchy(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "p = \"/home/charles/github/VNL-Brax-Imitation/transform_snips_250_clip_0.p\"\n",
    "\n",
    "with open(p, \"rb\") as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.angular_velocity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
